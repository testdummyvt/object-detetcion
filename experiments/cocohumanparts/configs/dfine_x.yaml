data_root: /home/ubuntu/datasets/cocohumanparts
work_dir: /home/ubuntu/experiments/cocohumanparts/dfine_x
callback_monitor: val/map_50
disable_infer_num_classes: false
engine:
  task: DETECTION
  device: auto
  num_devices: 1
data:
  task: DETECTION
  data_format: coco_instances
  train_subset:
    batch_size: 8
    subset_name: train
    transforms:
    - class_path: torchvision.transforms.v2.ToImage
    - class_path: torchvision.transforms.v2.RandomPhotometricDistort
      init_args:
        p: 0.5
    - class_path: torchvision.transforms.v2.RandomZoomOut
      init_args:
        fill: 0
    - class_path: otx.core.data.transform_libs.torchvision.RandomIoUCrop
      init_args:
        p: 0.8
    - class_path: torchvision.transforms.v2.SanitizeBoundingBoxes
      init_args:
        min_size: 1
    - class_path: otx.core.data.transform_libs.torchvision.RandomFlip
      init_args:
        prob: 0.5
    - class_path: otx.core.data.transform_libs.torchvision.Resize
      init_args:
        scale: $(input_size)
        transform_bbox: true
        keep_ratio: false
        is_numpy_to_tvtensor: true
    - class_path: otx.core.data.transform_libs.torchvision.PhotoMetricDistortion
      enable: false
      init_args:
        is_numpy_to_tvtensor: true
    - class_path: otx.core.data.transform_libs.torchvision.RandomAffine
      enable: false
      init_args:
        is_numpy_to_tvtensor: true
    - class_path: torchvision.transforms.v2.GaussianBlur
      enable: false
      init_args:
        kernel_size: 5
    - class_path: torchvision.transforms.v2.RandomVerticalFlip
      enable: false
    - class_path: torchvision.transforms.v2.ToDtype
      init_args:
        dtype: ${as_torch_dtype:torch.float32}
        scale: true
    - class_path: torchvision.transforms.v2.GaussianNoise
      enable: false
    transform_lib_type: TORCHVISION
    num_workers: 4
    sampler:
      class_path: otx.algo.samplers.balanced_sampler.BalancedSampler
      init_args: {}
    to_tv_image: true
  val_subset:
    batch_size: 8
    subset_name: val
    transforms:
    - class_path: torchvision.transforms.v2.ToImage
    - class_path: otx.core.data.transform_libs.torchvision.Resize
      init_args:
        scale: $(input_size)
        keep_ratio: false
        is_numpy_to_tvtensor: true
    - class_path: torchvision.transforms.v2.ToDtype
      init_args:
        dtype: ${as_torch_dtype:torch.float32}
        scale: true
    transform_lib_type: TORCHVISION
    num_workers: 2
    sampler:
      class_path: torch.utils.data.RandomSampler
      init_args: {}
    to_tv_image: true
  test_subset:
    batch_size: 8
    subset_name: test
    transforms:
    - class_path: torchvision.transforms.v2.ToImage
    - class_path: otx.core.data.transform_libs.torchvision.Resize
      init_args:
        scale: $(input_size)
        keep_ratio: false
        is_numpy_to_tvtensor: true
    - class_path: torchvision.transforms.v2.ToDtype
      init_args:
        dtype: ${as_torch_dtype:torch.float32}
        scale: true
    transform_lib_type: TORCHVISION
    num_workers: 2
    sampler:
      class_path: torch.utils.data.RandomSampler
      init_args: {}
    to_tv_image: true
  tile_config:
    enable_tiler: false
    enable_adaptive_tiling: true
    tile_size:
    - 400
    - 400
    overlap: 0.2
    iou_threshold: 0.45
    max_num_instances: 1500
    object_tile_ratio: 0.03
    sampling_ratio: 1.0
    with_full_img: false
  vpm_config:
    use_bbox: false
    use_point: false
  mem_cache_size: 1GB
  mem_cache_img_max_size: null
  image_color_channel: RGB
  stack_images: true
  include_polygons: false
  ignore_index: 255
  unannotated_items_ratio: 0.0
  auto_num_workers: false
  input_size:
  - 640
  - 640
  input_size_multiplier: 1
workspace:
  use_sub_dir: true
max_epochs: 100
deterministic: false
precision: 16-mixed
callbacks:
- class_path: otx.algo.callbacks.adaptive_early_stopping.EarlyStoppingWithWarmup
  init_args:
    min_delta: 0.001
    patience: 10
    verbose: false
    mode: max
    strict: true
    check_finite: true
    stopping_threshold: null
    divergence_threshold: null
    check_on_train_epoch_end: false
    log_rank_zero_only: false
    warmup_iters: 100
    warmup_epochs: 7
- class_path: lightning.pytorch.callbacks.RichProgressBar
  init_args:
    refresh_rate: 1
    leave: false
    theme:
      description: white
      progress_bar: '#6206E0'
      progress_bar_finished: '#6206E0'
      progress_bar_pulse: '#6206E0'
      batch_progress: white
      time: grey54
      processing_speed: grey70
      metrics: white
      metrics_text_delimiter: ' '
      metrics_format: .3f
    console_kwargs: null
- class_path: lightning.pytorch.callbacks.ModelCheckpoint
  init_args:
    dirpath: ''
    filename: checkpoints/epoch_{epoch:03d}
    verbose: false
    save_last: true
    save_top_k: 1
    save_weights_only: false
    mode: max
    auto_insert_metric_name: false
    every_n_train_steps: null
    train_time_interval: null
    every_n_epochs: null
    save_on_train_epoch_end: null
    enable_version_counter: true
- class_path: otx.algo.callbacks.iteration_timer.IterationTimer
  init_args:
    prog_bar: true
    on_step: false
    on_epoch: true
- class_path: otx.algo.callbacks.gpu_mem_monitor.GPUMemMonitor
- class_path: lightning.pytorch.callbacks.RichModelSummary
  init_args:
    max_depth: 1
- class_path: lightning.pytorch.callbacks.LearningRateMonitor
  init_args:
    logging_interval: epoch
    log_momentum: true
    log_weight_decay: false
- class_path: otx.algo.callbacks.adaptive_train_scheduling.AdaptiveTrainScheduling
  init_args:
    max_interval: 1
    decay: -0.025
    min_earlystop_patience: 5
    min_lrschedule_patience: 3
logger:
- class_path: lightning.pytorch.loggers.CSVLogger
  init_args:
    save_dir: ''
    name: csv/
    version: null
    prefix: ''
    flush_logs_every_n_steps: 100
- class_path: lightning.pytorch.loggers.TensorBoardLogger
  init_args:
    save_dir: ''
    name: tensorboard/
    version: null
    log_graph: false
    default_hp_metric: true
    prefix: ''
    sub_dir: null
    logdir: null
    comment: ''
    purge_step: null
    max_queue: 10
    flush_secs: 120
    filename_suffix: ''
    write_to_disk: true
    comet_config:
      disabled: true
resume: false
adaptive_bs: None
strategy: auto
num_nodes: 1
fast_dev_run: false
min_epochs: 1
max_steps: -1
overfit_batches: 0.0
check_val_every_n_epoch: 1
num_sanity_val_steps: 0
accumulate_grad_batches: 1
inference_mode: true
use_distributed_sampler: true
detect_anomaly: false
barebones: false
sync_batchnorm: false
reload_dataloaders_every_n_epochs: 0
model:
  class_path: otx.algo.detection.d_fine.DFine
  init_args:
    model_name: dfine_hgnetv2_x
    label_info: 80
    input_size:
    - 640
    - 640
    optimizer:
      class_path: torch.optim.AdamW
      init_args:
        lr: 0.00025
        betas:
        - 0.9
        - 0.999
        eps: 1.0e-08
        weight_decay: 0.000125
        amsgrad: false
        maximize: false
        capturable: false
        differentiable: false
    scheduler:
      class_path: otx.core.schedulers.LinearWarmupSchedulerCallable
      init_args:
        main_scheduler_callable:
          class_path: lightning.pytorch.cli.ReduceLROnPlateau
          init_args:
            monitor: val/map_50
            mode: max
            factor: 0.1
            patience: 6
            threshold: 0.0001
            threshold_mode: rel
            cooldown: 0
            min_lr: 0.0
            eps: 1.0e-08
        num_warmup_steps: 100
        warmup_interval: step
    metric: otx.core.metrics.fmeasure._mean_ap_f_measure_callable
    multi_scale: true
    torch_compile: false
    tile_config:
      enable_tiler: false
      enable_adaptive_tiling: true
      tile_size:
      - 400
      - 400
      overlap: 0.2
      iou_threshold: 0.45
      max_num_instances: 1500
      object_tile_ratio: 0.03
      sampling_ratio: 1.0
      with_full_img: false
